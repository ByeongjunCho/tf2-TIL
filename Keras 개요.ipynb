{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 간단한 모델 만들기\n",
    "### Sequential 모델\n",
    "* 케라스는 층(Layer)을 조합하여 모델(model)을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# 64개의 유닛을 가진 완전 연결 층을 모델에 추가합니다:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# 또 하나를 추가합니다:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# 10개의 출력 유닛을 가진 소프트맥스 층을 추가합니다:\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 층 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x131edcc7d48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시그모이드 활성화 층을 만듭니다:\n",
    "layers.Dense(64, activation='sigmoid')\n",
    "\n",
    "# 또는 다음도 가능합니다:\n",
    "layers.Dense(64, activation=tf.keras.activations.sigmoid)\n",
    "\n",
    "# 커널 행렬에 L1 규제가 적용된 선형 활성화 층. 하이퍼파라미터 0.01은 규제의 양을 조절합니다:\n",
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# 절편 벡터에 L2 규제가 적용된 선형 활성화 층. 하이퍼파라미터 0.01은 규제의 양을 조절합니다:\n",
    "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# 커널을 랜덤한 직교 행렬로 초기화한 선형 활성화 층:\n",
    "layers.Dense(64, kernel_initializer='orthogonal')\n",
    "\n",
    "# 절편 벡터를 상수 2.0으로 설정한 선형 활성화 층:\n",
    "layers.Dense(64, bias_initializer=tf.keras.initializers.Constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련과 평가\n",
    "### 훈련 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "# 64개의 유닛을 가진 완전 연결 층을 모델에 추가합니다:\n",
    "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "# 또 하나를 추가합니다:\n",
    "layers.Dense(64, activation='relu'),\n",
    "# 10개의 출력 유닛을 가진 소프트맥스 층을 추가합니다:\n",
    "layers.Dense(10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련을 설정하는 몇 가지 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 제곱 오차로 회귀 모델을 설정합니다.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='mse',       # 평균 제곱 오차\n",
    "              metrics=['mae'])  # 평균 절댓값 오차\n",
    "\n",
    "# 크로스엔트로피 손실 함수로 분류 모델을 설정합니다.\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 6,922\n",
      "Trainable params: 6,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋이 작은 경우 `numpy`배열을 메모리에 적제하여 모델을 훈련하고 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 182us/sample - loss: 24633.4509 - categorical_accuracy: 0.0930 - val_loss: 32977.4253 - val_categorical_accuracy: 0.0900\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 28666.3931 - categorical_accuracy: 0.0880 - val_loss: 33430.6459 - val_categorical_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 32619.4897 - categorical_accuracy: 0.0950 - val_loss: 52887.2494 - val_categorical_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 38515.1085 - categorical_accuracy: 0.0880 - val_loss: 37862.3223 - val_categorical_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 44787.7728 - categorical_accuracy: 0.0960 - val_loss: 34271.9062 - val_categorical_accuracy: 0.1300\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 48650.4742 - categorical_accuracy: 0.0900 - val_loss: 42789.4997 - val_categorical_accuracy: 0.0900\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 56322.4360 - categorical_accuracy: 0.1010 - val_loss: 42916.4697 - val_categorical_accuracy: 0.0600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 60483.4868 - categorical_accuracy: 0.1020 - val_loss: 70481.2472 - val_categorical_accuracy: 0.1100\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 67519.6369 - categorical_accuracy: 0.1050 - val_loss: 92677.6900 - val_categorical_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 73844.8894 - categorical_accuracy: 0.1110 - val_loss: 67515.7106 - val_categorical_accuracy: 0.0900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x131ed697548>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.data 데이터셋을 사용한 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 30 steps\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 81012.3467 - categorical_accuracy: 0.0979\n",
      "Epoch 2/10\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 75806.0156 - categorical_accuracy: 0.0625WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 300 batches). You may need to use the repeat() function when building your dataset.\n",
      " 2/30 [=>............................] - ETA: 1s - loss: 84836.4766 - categorical_accuracy: 0.0750"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x131ed24bcc8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 `Dataset` 객체를 만듭니다:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "# Dataset에서 `fit` 메서드를 호출할 때 `steps_per_epoch` 설정을 잊지 마세요.\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `steps_per_epoch` => 다음 에포크로 넘어가기 전 모델이 수행할 훈련 단계 횟수\n",
    "* `Dataset`이 배치 데이터를 생성하기 때문에 `batch_size`가 필요하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 91152.2454 - categorical_accuracy: 0.0810 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 98027.9548 - categorical_accuracy: 0.0940 - val_loss: 68893.5801 - val_categorical_accuracy: 0.0900\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 100850.9826 - categorical_accuracy: 0.0990 - val_loss: 103019.8691 - val_categorical_accuracy: 0.0600\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 111894.9178 - categorical_accuracy: 0.0930 - val_loss: 89721.3672 - val_categorical_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 121002.6204 - categorical_accuracy: 0.1080 - val_loss: 144599.7734 - val_categorical_accuracy: 0.1200\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 135408.1754 - categorical_accuracy: 0.0950 - val_loss: 140199.8125 - val_categorical_accuracy: 0.1300\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 136967.7442 - categorical_accuracy: 0.0950 - val_loss: 190583.8516 - val_categorical_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 150564.2125 - categorical_accuracy: 0.0900 - val_loss: 182880.7578 - val_categorical_accuracy: 0.1200\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 163622.8285 - categorical_accuracy: 0.0980 - val_loss: 142440.0195 - val_categorical_accuracy: 0.0900\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 169876.5236 - categorical_accuracy: 0.1040 - val_loss: 182292.7617 - val_categorical_accuracy: 0.0600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x131eda9ae08>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "\n",
    "model.fit(dataset, epochs=10,\n",
    "          validation_data=val_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
