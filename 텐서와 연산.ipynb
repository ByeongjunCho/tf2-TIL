{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서와 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow 2.x부터는 즉시 실행(eager execution)이 기본 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서\n",
    "텐서는 다차원 배열입니다. 넘파이(NumPy) ndarray 객체와 비슷하며, tf.Tensor 객체는 데이터 타입과 크기를 가지고 있습니다. 또한 tf.Tensor는 GPU 같은 가속기 메모리에 상주할 수 있습니다. 텐서플로는 텐서를 생성하고 이용하는 풍부한 연산 라이브러리(tf.add, tf.matmul, tf.linalg.inv 등.)를 제공합니다. 이러한 연산은 자동으로 텐서를 파이썬 네이티브(native) 타입으로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor(25, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.add(1,2))\n",
    "print(tf.add([1, 2], [3,4]))\n",
    "print(tf.square(5))\n",
    "print(tf.reduce_sum([1, 2, 3]))\n",
    "\n",
    "# 연산자 오버로딩 지원\n",
    "print(tf.square(2) + tf.square(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[2 3]], shape=(1, 2), dtype=int32)\n",
      "(1, 2)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.matmul([[1]], [[2,3]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 넘파이 호환성\n",
    "* tensorflow는 numpy 배열을 자동으로 텐서로 변환\n",
    "* numpy 연산은 자동으로 텐서를 numpy array로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow 연산은 자동으로 numpy 배열을 텐서로 변환\n",
      "tf.Tensor(\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n",
      "numpy 연산은 자동으로 텐서를 numpy 배열로 변환\n",
      "[[43. 43. 43.]\n",
      " [43. 43. 43.]\n",
      " [43. 43. 43.]]\n",
      ".numpy() 메서드는 텐서를 numpy 배열로 변환\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print(\"tensorflow 연산은 자동으로 numpy 배열을 텐서로 변환\")\n",
    "tensor = tf.math.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "\n",
    "print(\"numpy 연산은 자동으로 텐서를 numpy 배열로 변환\")\n",
    "print(np.add(tensor, 1))\n",
    "\n",
    "print(\".numpy() 메서드는 텐서를 numpy 배열로 변환\")\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU 가속\n",
    "텐서플로우는 연산을 위해 CPU 또는 GPU를 사용할 것인지 자동으로 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 사용이 가능한가 : \n",
      "True\n",
      "텐서가 GPU #0에 있는가 : \n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.uniform([3, 3])\n",
    "\n",
    "print(\"GPU 사용이 가능한가 : \")\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "print(\"텐서가 GPU #0에 있는가 : \")\n",
    "print(x.device.endswith('GPU:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 장치 이름\n",
    "텐서를 구성하고 있는 호스트 장치의 풀네임을 제공. 텐서가 N번째 GPU에 있다면 GPU:N으로 반환.\n",
    "### 명시적 장치 배치\n",
    "Tensorflow는 연산 실행을 이해 장치를 자동으로 결정함. 사용자는 `tf.device`를 사용해 특정 장치에 명시적 배치 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On CPU:\n",
      "10 loops: 75.07ms\n",
      "On GPU:\n",
      "10 loops: 493.45ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def time_matmul(x):\n",
    "    start = time.time()\n",
    "    for loop in range(10):\n",
    "        tf.matmul(x, x)\n",
    "    \n",
    "    result = time.time() - start\n",
    "    \n",
    "    print(\"10 loops: {:0.2f}ms\".format(1000*result))\n",
    "    \n",
    "# CPU에서 강제 실행\n",
    "print(\"On CPU:\")\n",
    "with tf.device(\"CPU:0\"):\n",
    "    x = tf.random.uniform([1000, 1000])\n",
    "    assert x.device.endswith(\"CPU:0\")\n",
    "    time_matmul(x)\n",
    "\n",
    "# GPU #0가 이용 가능한 경우 GPU #0에서 강제 실행\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"On GPU:\")\n",
    "    with tf.device(\"GPU:0\"):\n",
    "        x = tf.random.uniform([1000, 1000])\n",
    "        assert x.device.endswith(\"GPU:0\")\n",
    "        time_matmul(x)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋\n",
    "이번에는 모델에 데이터를 제공하기 위한 파이프라인을 구축하기 위해 `tf.data.Dataset` API를 사용해볼 것입니다.\n",
    "\n",
    "`tf.data.Dataset API`는 모델을 훈련시키고 평가 루프를 제공할, 간단하고 재사용 가능한 모듈로부터 복잡한 입력 파이프라인을 구축하기 위해 사용됩니다.\n",
    "\n",
    "### 소스 데이터셋 생성\n",
    "굉장히 유용한 함수중 하나인 `Dataset.from_tensors`, `Dataset.from_tensor_slices`와 같은 팩토리(factory) 함수 중 하나를 사용하거나 파일로부터 읽어들이는 객체인 `TextLineDataset` 또는 `TFRecordDataset`를 사용하여 소스 데이터셋을 생성하세요. 더 많은 정보를 위해서 텐서플로 데이터셋 가이드를 참조하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.int32>\n"
     ]
    }
   ],
   "source": [
    "ds_tensors = tf.data.Dataset.from_tensor_slices([1,2,3,4,5,6])\n",
    "print(ds_tensors)\n",
    "\n",
    "# CSV 파일을 생성\n",
    "import tempfile\n",
    "_, filename = tempfile.mkstemp()\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(\"\"\"Line 1\n",
    "    Line 2\n",
    "    Line 3\n",
    "    \"\"\")\n",
    "    \n",
    "ds_file = tf.data.TextLineDataset(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변환 적용\n",
    "`map`, `batch`, `shuffle`같은 변환 함수를 사용하여 데이터셋에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tensors = ds_tensors.map(tf.square).shuffle(2).batch(2)\n",
    "\n",
    "ds_file = ds_file.batch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 반복\n",
    "`tf.data.Dataset`은 레코드 순회를 지원하는 반복가능한 객체이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_tensors 요소: \n",
      "tf.Tensor([1 9], shape=(2,), dtype=int32)\n",
      "tf.Tensor([16 25], shape=(2,), dtype=int32)\n",
      "tf.Tensor([36  4], shape=(2,), dtype=int32)\n",
      "\n",
      "ds_file 요소:\n",
      "tf.Tensor([b'Line 1' b'    Line 2'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'    Line 3' b'    '], shape=(2,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print('ds_tensors 요소: ')\n",
    "for x in ds_tensors:\n",
    "    print(x)\n",
    "\n",
    "print('\\nds_file 요소:')\n",
    "for x in ds_file:\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
